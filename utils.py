
import os
import openai
import json
import time
import re
import pandas as pd
import numpy as np
from openai import AzureOpenAI, OpenAI 
import os


client = AzureOpenAI(
    api_key = os.getenv("API_KEY"),
    azure_endpoint =  os.getenv("ENDPOINT"),
    api_version= os.getenv("API_VERSION")
)


def LLM(prompt, temp, model_name):
    flag = 0
    sleep = 1
    while(flag==0):
        try: 
            messages = []
            messages.append({"role": "user", "content": prompt})
            response = client.chat.completions.create( model=model_name,  messages=messages, temperature=temp)
            flag = 1
        except Exception as e: 
            print(f"Error: {e}")
            time.sleep(sleep)
    return response.choices[0].message.content

def feedback_one_example(task, prompt, question, answer, pred_answer, cot):
    Examples = ""
    for i in range(len(pred_answer)):
        Examples += f'''
            ### Question
                {question[i]}
            ### Answer
                {answer[i]}
            ### Predicted answer
                {pred_answer[i]}
            ### Explanation
                {cot[i]}
        '''


    input_prompt = f'''
    I AM GIVING YOU AN INPUT PROMPT TO SOLVE A GIVEN TASK USING A LANGUAGE MODEL.
    I will give you a few questions along with the explanations generated by the language model while solving the questions.
    The questions are answered wrong by the language model. You have to tell me what information is missing in the prompt that would have helped the language model to generate better explanations. 

    Steps to find what is wrong in individual questions:
    1. See the questions
    2. Verify the chain of thought used to answer the questions
    3. What ever step it makes a mistake, find what concept is used at that step
    4. Add that concept into the prompt, maybe add an example to make the concept more clear
    5. Finally verify that your addition makes the reasoning correct or not.
    6. Try adding concepts as well as examples how to solve fr the concept.

    Steps to propose a common feedback for all problems:
    1. Identify the general problem that is being solved by all the feedbacks. 

    2. Once you have identified the problem, try to make a new feedback that covers most of the feedbacks given. Let's say the problem in the first feedback is the absence of methods to solve linear equation and in the second feedback it is the method to inverse a matrix. You know that both of these problems can be caused by adding how to solve convert a matrix into row rediced echolon form. So, add that.

    3. Try and validate your feedback. Once, you have a feedback try to see if it covers every feedback, if it does not cover any feedback, add that to your new feedback.

    4. Give only one final feedback that applies to all.


    You can modify the prompt using the following functions:
    add_section(sectioname)
    add_subsection(section_name, subsection_name)
    set_section_content(section_name, new_content)
    set_subsection_content(section_name, subsection_name, new_content)
    delete_section(section_name)
    delete_subsection(section_name, subsection_name)

    Remember to give the feedback in form of these functions, the feedback cannot contain more than two functions.

    ## Task
     {task}
    ## Prompt
     {prompt}
    {Examples}

    Now, Let us follow the steps and think what is wrong in the chain of thought solutions.
    '''

    input_prompt = f'''
    You are a teacher and you have to give feedback to your students on their answers. 
    
    You are teaching hate speach detection to your students. You are given a question and it's answer. You are also given the explanations written by your students while solving the questions. 
    
    The questions are answered wrong by the students. You have to tell why is the solution wrong and what information is can be added to the in the Background Knowledge part that would have helped the student to write better explanations.

    Be explicit and tell the exact information that can be dded without further modification / addition. 

    You can  add a section, add a subsection, set the content of a section, set the content of a subsection, delete a section or delete a subsection in the background knowledge part.

    Give very granular feedbacks, like if the student has made a mistake in the calculation, then tell what is the mistake in the calculation and how to correct it, if the student has made a mistake in the concept, then tell what is the mistake in the concept and how to correct it. 

    You can also give examples to make the concept more clear.

    ## Background Knowledge
     {prompt}

    {Examples}

    Now, it is your turn to give feedbacks to the students.
    '''
    output = LLM(input_prompt, 0, "gpt-4")
    return output

def combine_multiple_feedbacks(edits):
    input_prompt = f'''
    You are given a set of feedbacks in form of instructions for some problems. The set feedbacks for each problem separated by =========== symbol. 
    You have to summarize the feedbacks into a final feedback.

    To achieve your task, try to follow the following steps;
    1. Identify the general problem that is being solved by all the feedbacks. 

    2. Once you have identified the problem, try to make a new feedback that covers most of the feedbacks given. Let's say the problem in the first feedback is the absence of methods to solve linear equation and in the second feedback it is the method to inverse a matrix. You know that both of these problems can be caused by adding how to solve convert a matrix into row rediced echolon form. So, add that.

    3. Try and validate your feedback. Once, you have a feedback try to see if it covers every feedback, if it does not cover any feedback, add that to your new feedback.

    4. You can add specifics like examples, definitions etc make sure that the feedback is enough to be directly added without any modification.

    You may use the following function templates-

    add_section(sectioname)
    add_subsection(section_name, subsection_name)
    set_section_content(section_name, new_content)
    set_subsection_content(section_name, subsection_name, new_content)
    delete_section(section_name)
    delete_subsection(section_name, subsection_name)

    Your summary cannot include more than four functions. Make sure that the content is useful, not just a very general statement. Something specific.

    Instructions:
    {edits}

    Summary:
    '''
    output = LLM(input_prompt, 0, "gpt-4")
    return output

def apply_edits(prompt, edits, specific_edits, expert_llm):

    input_prompt = f'''
    You are given an input prompt and a feedback, you have to incorporate the feedback into the input prompt and output the final prompt.
    An example of the task is given below

    ### Input Prompt
    Introduction: In this task you have to answer the given question.

    ### Feedback
    The background knowledge is incomplete, it does not include what are the factors that affect the water usage and how many water sources are there.
    \\add_subsection("Background Knowledge")
    \\add_subsection_content(water usage depends on the population, climate, economic development, and availability of water sources. There are two sources of water, surface water and groundwater.)

    ### Final Prompt
    Introduction: In this task you have to answer the given question.
    Background Knowledge: water usage depends on the population, climate, economic development, and availability of water sources. There are two sources of water, surface water and groundwater.

    Only output the final prompt nothing else. 

    ### INPUT PROMPT
    {prompt}

    ### FEEDBACK
    {edits}


    ### FINAL PROMPT
    '''
    output = LLM(input_prompt, 0, expert_llm)

    prompt = f'''
    You are given a paragraph that has some feedback followed by the actual content. Your task is to provide just the acutal content from the entire paragraph in the format it was in the paragraph.

    # Paragraph: 
    {output}

    # Actual content:
    '''

    return output

def feedback_with_history(task, prompt,  question, answer, pred_answer, cot, history, expert_llm):
    Examples = ""
    for i in range(len(pred_answer)):
          Examples += f'''
            ### Question
                {question[i]}
            ### True Answer
                {answer[i]}
            ### Student's answer
                {pred_answer[i]}
            ### Explanation
                {cot[i]}
                '''
        
    history_string = ""
    for i in range(len(history)):
        history_string += f'''
            ### Edit Proposed
                {history[i][0]}
            ### Accuracy Change
                {history[i][1]}
                '''
    input_prompt = f'''
    You are a teacher and you have to give feedback to your students on their answers. 
    
    You are teaching how to solve math problems to your students. You are given a question, it's true answer and answer given by student. You are also given the explanations written by your students while solving the questions. 
    
    The questions are answered wrong by the students. You have to tell why is the solution wrong and what information is can be added to the in the Background Knowledge part that would have helped the student to write better explanations.

    ## IMPORTANT: You are also given a history of changes you made to the background knowledge part and the change in student's accuracy after making the change. You have to use this history to make your feedback.

    Be explicit and tell the exact information that can be added without further modification / addition. 

    ### IMPORTANT: Give feedback in form of instructions like  add a section, add a subsection, set the content of a section, set the content of a subsection, delete a section or delete a subsection in the background knowledge part.

    Give very granular feedbacks, like if the student has made a mistake in the calculation, then tell what is the mistake in the calculation and how to correct it, if the student has made a mistake in the concept, then tell what is the mistake in the concept and how to correct it. 

    ## Background Knowledge
     {prompt}

    ## History
    {history_string}



    {Examples}

    Now, it is your turn to give feedbacks to the students.
    You can only provide a one line feedback.
    '''
    
    # You can also give examples to make the concept more clear.
    output = LLM(input_prompt, 0, expert_llm)

    return output

def combine_multiple_feedbacks_with_examples(edits, wrong_examples, expert_llm):
    wrong_examples_string = ""
    for i in range(len(wrong_examples)):
            wrong_examples_string += f'''
            ### Question
                {wrong_examples[i]}
                '''

    input_prompt = f'''
    You are given a set of feedbacks for some problems. The set feedbacks for each problem separated by =========== symbol. 
    You have to summarize the feedbacks into a final feedback. 
    You are also given a set of wrong questions. You need to tell which edit can be applied to aid the student in solving the wrong question.

    To achieve your task, try to follow the following steps;
    1. Identify the general problem that is being solved by all the feedbacks. 
    2. Once you have identified the problem, try to make a new feedback that covers most of the feedbacks given. Let's say the problem in the first feedback is the absence of methods to solve linear equation and in the second feedback it is the method to inverse a matrix. You know that both of these problems can be caused by adding how to solve convert a matrix into row rediced echolon form. So, add that.
    3. Try and validate your feedback. Once, you have a feedback try to see if it covers every feedback, if it does not cover any feedback, add that to your new feedback.
    4. See the wrong questions and try to identify what is the problem in the question. If the problem is not covered by your feedback, add that to your feedback.
    5. You can add specifics like examples, definitions etc make sure that the feedback is enough to be directly added without any modification.

    You may use the following function templates-

    add_section(sectioname)
    add_subsection(section_name, subsection_name)
    set_section_content(section_name, new_content)
    set_subsection_content(section_name, subsection_name, new_content)
    delete_section(section_name)
    delete_subsection(section_name, subsection_name)

    Your summary cannot include more than four functions. Make sure that the content is useful, not just a very general statement. Something specific.

    Instructions:
    {edits}

    Wrong Questions:
    {wrong_examples_string}

    Summary:
    '''
    output = LLM(input_prompt, 0, expert_llm)
    return output


    











